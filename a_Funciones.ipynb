{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVe6eUoUmczwFlTz7uwwpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leidysguerrero120/Trabajo-Analitica-3---RRHH/blob/main/a_Funciones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Importamos las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "###Función para ejecutar un archivo SQL que contenga múltiples consultas\n",
        "def ejecutar_consultas_sql(nombre_archivo, cursor):\n",
        "    with open(nombre_archivo, 'r') as archivo_sql:\n",
        "        contenido_sql = archivo_sql.read()\n",
        "    cursor.executescript(contenido_sql)\n",
        "\n",
        "###Función para imputar datos numéricos con la mediana y categóricos con la moda\n",
        "def imputar_datos(df, columnas_categoricas):\n",
        "    df_cat = df[columnas_categoricas]\n",
        "    df_num = df.loc[:, ~df.columns.isin(columnas_categoricas)]\n",
        "\n",
        "    imputador_num = SimpleImputer(strategy='median')\n",
        "    imputador_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "    imputador_num.fit(df_num)\n",
        "    imputador_cat.fit(df_cat)\n",
        "\n",
        "    datos_num = imputador_num.transform(df_num)\n",
        "    datos_cat = imputador_cat.transform(df_cat)\n",
        "\n",
        "    df_num = pd.DataFrame(datos_num, columns=df_num.columns)\n",
        "    df_cat = pd.DataFrame(datos_cat, columns=df_cat.columns)\n",
        "\n",
        "    df = pd.concat([df_num, df_cat], axis=1)\n",
        "    return df\n",
        "\n",
        "###Función para seleccionar variables relevantes usando diferentes modelos\n",
        "def seleccionar_variables(modelos, X, y, umbral):\n",
        "    nombres_variables = np.array([])\n",
        "    for modelo in modelos:\n",
        "        modelo.fit(X, y)\n",
        "        seleccion = SelectFromModel(modelo, prefit=True, threshold=umbral)\n",
        "        nombres = modelo.feature_names_in_[seleccion.get_support()]\n",
        "        nombres_variables = np.append(nombres_variables, nombres)\n",
        "        nombres_variables = np.unique(nombres_variables)\n",
        "\n",
        "    return nombres_variables\n",
        "\n",
        "###Función para evaluar modelos usando validación cruzada\n",
        "def evaluar_modelos(modelos, metrica, X, y, cv):\n",
        "    resultados_modelos = pd.DataFrame()\n",
        "    for modelo in modelos:\n",
        "        puntuaciones = cross_val_score(modelo, X, y, scoring=metrica, cv=cv)\n",
        "        resultados = pd.DataFrame(puntuaciones)\n",
        "        resultados_modelos = pd.concat([resultados_modelos, resultados], axis=1)\n",
        "\n",
        "    resultados_modelos.columns = [\"Regresión_Logística\", \"Árboles_Decisión\", \"Bosque_Aleatorio\", \"Ajuste_Gradiente\"]\n",
        "    return resultados_modelos\n",
        "\n",
        "###Función para preparar datos: imputación, creación de variables dummy y escalado\n",
        "def transformar_datos(df):\n",
        "    columnas_categoricas = joblib.load(\"columnas_categoricas.pkl\")\n",
        "    columnas_dummies = joblib.load(\"columnas_dummies.pkl\")\n",
        "    nombres_variables = joblib.load(\"nombres_variables.pkl\")\n",
        "    escalador = joblib.load(\"escalador.pkl\")\n",
        "\n",
        "    df = imputar_datos(df, columnas_categoricas)\n",
        "    df_dummies = pd.get_dummies(df, columns=columnas_dummies)\n",
        "    df_dummies = df_dummies.loc[:, ~df_dummies.columns.isin(['perf_2023', 'EmpID2'])]\n",
        "    datos_escalados = escalador.transform(df_dummies)\n",
        "    X = pd.DataFrame(datos_escalados, columns=df_dummies.columns)\n",
        "    X = X[nombres_variables]\n",
        "\n",
        "    return X\n",
        "\n",
        "###Función para imputar valores nulos con la moda de la variable\n",
        "def imputar_por_moda(df, variables):\n",
        "    for variable in variables:\n",
        "        moda = df[variable].mode()[0]\n",
        "        df[variable].fillna(moda, inplace=True)\n",
        "        nulos_restantes = df[variable].isnull().sum()\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "Ks7SXJrS_YyN"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}